<!DOCTYPE html>
<html lang="en">

<head>
  <title>About · JXIN&#39;s Home</title>
  <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="color-scheme" content="light dark">




<meta name="author" content="Jie Xin">
<meta name="description" content="I&rsquo;m a senior compute architect at NVIDIA, focused on accelerating Deep Learning software stack on cutting-edge GPUs such as Hopper and Blackwell. Currently, I am engaged in developing a deep learning compiler and enhancing end-to-end training performance. In my spare time, I maintain a keen interest in emerging deep learning algorithms, including embodied intelligence, AI4Science, LLM and graphics.

  Some summarizes of my working:
  
    
    Link to heading
  


  Part of my contribution on Deep Learning Compilers:
  
    
    Link to heading
  


Fuser (2022): Support graphOps like gather/scatter/index_select. code blog
pytorch_geometric (2022): Add TorchScript support for PyG community. code


  Part of my contribution on Deep Learning models and frameworks for public users:
  
    
    Link to heading
  


Openfold (2023): MLPerf Training HPC Benchmark Suite Results, round v3.1; code blog paper
GPT3 (2023): MLPerf Training Benchmark Suite Results, round v4.0; Support arbitrary combinations of parallel orders. megatron-lm nemo


  Part of my contribution on fast kernels:
  
    
    Link to heading
  


SpMM optimization (2021): Champion of the Graph Challenge 2021 code paper blog
K-Truss decomposition (2021) paper
">
<meta name="keywords" content="blog,developer,personal">



  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="About">
  <meta name="twitter:description" content="I’m a senior compute architect at NVIDIA, focused on accelerating Deep Learning software stack on cutting-edge GPUs such as Hopper and Blackwell. Currently, I am engaged in developing a deep learning compiler and enhancing end-to-end training performance. In my spare time, I maintain a keen interest in emerging deep learning algorithms, including embodied intelligence, AI4Science, LLM and graphics.
Some summarizes of my working: Link to heading Part of my contribution on Deep Learning Compilers: Link to heading Fuser (2022): Support graphOps like gather/scatter/index_select. code blog pytorch_geometric (2022): Add TorchScript support for PyG community. code Part of my contribution on Deep Learning models and frameworks for public users: Link to heading Openfold (2023): MLPerf Training HPC Benchmark Suite Results, round v3.1; code blog paper GPT3 (2023): MLPerf Training Benchmark Suite Results, round v4.0; Support arbitrary combinations of parallel orders. megatron-lm nemo Part of my contribution on fast kernels: Link to heading SpMM optimization (2021): Champion of the Graph Challenge 2021 code paper blog K-Truss decomposition (2021) paper">

<meta property="og:url" content="https://ftxj.github.io/about/">
  <meta property="og:site_name" content="JXIN&#39;s Home">
  <meta property="og:title" content="About">
  <meta property="og:description" content="I’m a senior compute architect at NVIDIA, focused on accelerating Deep Learning software stack on cutting-edge GPUs such as Hopper and Blackwell. Currently, I am engaged in developing a deep learning compiler and enhancing end-to-end training performance. In my spare time, I maintain a keen interest in emerging deep learning algorithms, including embodied intelligence, AI4Science, LLM and graphics.
Some summarizes of my working: Link to heading Part of my contribution on Deep Learning Compilers: Link to heading Fuser (2022): Support graphOps like gather/scatter/index_select. code blog pytorch_geometric (2022): Add TorchScript support for PyG community. code Part of my contribution on Deep Learning models and frameworks for public users: Link to heading Openfold (2023): MLPerf Training HPC Benchmark Suite Results, round v3.1; code blog paper GPT3 (2023): MLPerf Training Benchmark Suite Results, round v4.0; Support arbitrary combinations of parallel orders. megatron-lm nemo Part of my contribution on fast kernels: Link to heading SpMM optimization (2021): Champion of the Graph Challenge 2021 code paper blog K-Truss decomposition (2021) paper">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="website">




<link rel="canonical" href="https://ftxj.github.io/about/">


<link rel="preload" href="/fonts/fa-brands-400.woff2" as="font" type="font/woff2" crossorigin>
<link rel="preload" href="/fonts/fa-regular-400.woff2" as="font" type="font/woff2" crossorigin>
<link rel="preload" href="/fonts/fa-solid-900.woff2" as="font" type="font/woff2" crossorigin>


  
  
  <link rel="stylesheet" href="/css/coder.min.320f775dc23c4eaba9df40ebced622292869c0437f4d5d744c43e5fe34882f03.css" integrity="sha256-Mg93XcI8Tqup30DrztYiKShpwEN/TV10TEPl/jSILwM=" crossorigin="anonymous" media="screen" />






  
    
    
    <link rel="stylesheet" href="/css/coder-dark.min.a00e6364bacbc8266ad1cc81230774a1397198f8cfb7bcba29b7d6fcb54ce57f.css" integrity="sha256-oA5jZLrLyCZq0cyBIwd0oTlxmPjPt7y6KbfW/LVM5X8=" crossorigin="anonymous" media="screen" />
  



 




<link rel="icon" type="image/svg+xml" href="/images/favicon.svg" sizes="any">
<link rel="icon" type="image/png" href="/images/favicon-32x32.png" sizes="32x32">
<link rel="icon" type="image/png" href="/images/favicon-16x16.png" sizes="16x16">

<link rel="apple-touch-icon" href="/images/apple-touch-icon.png">
<link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">

<link rel="manifest" href="/site.webmanifest">
<link rel="mask-icon" href="/images/safari-pinned-tab.svg" color="#5bbad5">


<link rel="alternate" type="application/rss+xml" href="/about/index.xml" title="JXIN's Home" />







</head>






<body class="preload-transitions colorscheme-auto">
  
<div class="float-container">
    <a id="dark-mode-toggle" class="colorscheme-toggle">
        <i class="fa-solid fa-adjust fa-fw" aria-hidden="true"></i>
    </a>
</div>


  <main class="wrapper">
    <nav class="navigation">
  <section class="container">
    
    <a class="navigation-title" href="https://ftxj.github.io/">
      JXIN&#39;s Home
    </a>
    
    
      <input type="checkbox" id="menu-toggle" />
      <label class="menu-button float-right" for="menu-toggle">
        <i class="fa-solid fa-bars fa-fw" aria-hidden="true"></i>
      </label>
      <ul class="navigation-list">
        
          
            <li class="navigation-item">
              <a class="navigation-link " href="/about/">About</a>
            </li>
          
        
        
      </ul>
    
  </section>
</nav>


    <div class="content">
      
  <section class="container list">
  <header>
    <h1 class="title">
      <a class="title-link" href="https://ftxj.github.io/about/">About</a>
    </h1>
  </header>
  <p>I&rsquo;m a senior compute architect at NVIDIA, focused on accelerating Deep Learning software stack on cutting-edge GPUs such as Hopper and Blackwell. Currently, I am engaged in developing a deep learning compiler and enhancing end-to-end training performance. In my spare time, I maintain a keen interest in emerging deep learning algorithms, including embodied intelligence, AI4Science, LLM and graphics.</p>
<h2 id="some-summarizes-of-my-working">
  Some summarizes of my working:
  <a class="heading-link" href="#some-summarizes-of-my-working">
    <i class="fa-solid fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h2>
<h3 id="part-of-my-contribution-on-deep-learning-compilers">
  Part of my contribution on Deep Learning Compilers:
  <a class="heading-link" href="#part-of-my-contribution-on-deep-learning-compilers">
    <i class="fa-solid fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h3>
<ul>
<li><strong>Fuser (2022)</strong>: Support graphOps like gather/scatter/index_select. <a href="https://github.com/pytorch/pytorch/pulls?q=is%3Apr&#43;author%3Aftxj&#43;fuser"  class="external-link" target="_blank" rel="noopener">code</a> <a href="https://ftxj.github.io/2022/08/08/pytorch-fuser/"  class="external-link" target="_blank" rel="noopener">blog</a></li>
<li><strong>pytorch_geometric (2022)</strong>: Add TorchScript support for PyG community. <a href="https://github.com/pyg-team/pytorch_geometric/pulls?q=is%3Apr&#43;author%3Aftxj"  class="external-link" target="_blank" rel="noopener">code</a></li>
</ul>
<h3 id="part-of-my-contribution-on-deep-learning-models-and-frameworks-for-public-users">
  Part of my contribution on Deep Learning models and frameworks for public users:
  <a class="heading-link" href="#part-of-my-contribution-on-deep-learning-models-and-frameworks-for-public-users">
    <i class="fa-solid fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h3>
<ul>
<li><strong>Openfold (2023)</strong>: MLPerf Training HPC Benchmark Suite Results, round v3.1; <a href="https://github.com/mlcommons/hpc_results_v3.1/tree/main/NVIDIA/benchmarks/openfold/implementations/pytorch"  class="external-link" target="_blank" rel="noopener">code</a> <a href="https://developer.nvidia.com/blog/new-mlperf-hpc-v3-1-results-deliver-strong-performance-and-energy-efficiency-at-scale/"  class="external-link" target="_blank" rel="noopener">blog</a> <a href="https://arxiv.org/abs/2403.06840"  class="external-link" target="_blank" rel="noopener">paper</a></li>
<li><strong>GPT3 (2023)</strong>: MLPerf Training Benchmark Suite Results, round v4.0; Support arbitrary combinations of parallel orders. <a href="https://github.com/NVIDIA/Megatron-LM/pull/738"  class="external-link" target="_blank" rel="noopener">megatron-lm</a> <a href="https://github.com/NVIDIA/NeMo/pull/8621"  class="external-link" target="_blank" rel="noopener">nemo</a></li>
</ul>
<h3 id="part-of-my-contribution-on-fast-kernels">
  Part of my contribution on fast kernels:
  <a class="heading-link" href="#part-of-my-contribution-on-fast-kernels">
    <i class="fa-solid fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h3>
<ul>
<li><strong>SpMM optimization (2021)</strong>: Champion of the Graph Challenge 2021 <a href="https://github.com/ftxj/BLAS-SpGEMM"  class="external-link" target="_blank" rel="noopener">code</a> <a href="https://arxiv.org/abs/2201.03347"  class="external-link" target="_blank" rel="noopener">paper</a> <a href="https://ftxj.github.io/2021/11/13/graphChallenge2021/"  class="external-link" target="_blank" rel="noopener">blog</a></li>
<li><strong>K-Truss decomposition (2021)</strong> <a href="https://ieeexplore.ieee.org/document/9651491"  class="external-link" target="_blank" rel="noopener">paper</a></li>
</ul>

  <ul>
    
  </ul>
  






</section>


    </div>

    <footer class="footer">
  <section class="container">
    ©
    
      2019 -
    
    2025
     Jie Xin 
    ·
    
    Powered by <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a> & <a href="https://github.com/luizdepra/hugo-coder/" target="_blank" rel="noopener">Coder</a>.
    
  </section>
</footer>

  </main>

  

  
  
  <script src="/js/coder.min.6ae284be93d2d19dad1f02b0039508d9aab3180a12a06dcc71b0b0ef7825a317.js" integrity="sha256-auKEvpPS0Z2tHwKwA5UI2aqzGAoSoG3McbCw73gloxc="></script>
  

  

  


  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  
</body>

</html>

<!DOCTYPE html>
<html lang="en">

<head>
  <title>
  About · JXIN&#39;s Home
</title>
  <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="color-scheme" content="light dark">




<meta name="author" content="Jie Xin">
<meta name="description" content="I’m a compute architect at NVIDIA, focused on accelerating Deep Learning software stack on cutting-edge GPUs such as Hopper and Blackwell. Currently, I am engaged in developing a deep learning compiler and enhancing end-to-end training performance. In my spare time, I maintain a keen interest in emerging deep learning algorithms, including embodied intelligence, AI4Science, LLM and graphics.
Some summarizes of my working:
Part of my contribution on Deep Learning Compilers:">
<meta name="keywords" content="blog,developer,personal">


  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="About">
  <meta name="twitter:description" content="I’m a compute architect at NVIDIA, focused on accelerating Deep Learning software stack on cutting-edge GPUs such as Hopper and Blackwell. Currently, I am engaged in developing a deep learning compiler and enhancing end-to-end training performance. In my spare time, I maintain a keen interest in emerging deep learning algorithms, including embodied intelligence, AI4Science, LLM and graphics.
Some summarizes of my working:
Part of my contribution on Deep Learning Compilers:">

<meta property="og:url" content="https://ftxj.github.io/about/about/">
  <meta property="og:site_name" content="JXIN&#39;s Home">
  <meta property="og:title" content="About">
  <meta property="og:description" content="I’m a compute architect at NVIDIA, focused on accelerating Deep Learning software stack on cutting-edge GPUs such as Hopper and Blackwell. Currently, I am engaged in developing a deep learning compiler and enhancing end-to-end training performance. In my spare time, I maintain a keen interest in emerging deep learning algorithms, including embodied intelligence, AI4Science, LLM and graphics.
Some summarizes of my working:
Part of my contribution on Deep Learning Compilers:">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:published_time" content="2024-08-08T01:02:27+08:00">
    <meta property="article:modified_time" content="2024-08-08T01:02:27+08:00">




<link rel="canonical" href="https://ftxj.github.io/about/about/">


<link rel="preload" href="/fonts/fa-brands-400.woff2" as="font" type="font/woff2" crossorigin>
<link rel="preload" href="/fonts/fa-regular-400.woff2" as="font" type="font/woff2" crossorigin>
<link rel="preload" href="/fonts/fa-solid-900.woff2" as="font" type="font/woff2" crossorigin>


  
  
  <link rel="stylesheet" href="/about/css/coder.min.38c4552ac40f9ae3408bad40358f654ebd8804412fe74ed56f2d6c8a7af82dd3.css" integrity="sha256-OMRVKsQPmuNAi61ANY9lTr2IBEEv507Vby1sinr4LdM=" crossorigin="anonymous" media="screen" />






  
    
    
    <link rel="stylesheet" href="/about/css/coder-dark.min.a00e6364bacbc8266ad1cc81230774a1397198f8cfb7bcba29b7d6fcb54ce57f.css" integrity="sha256-oA5jZLrLyCZq0cyBIwd0oTlxmPjPt7y6KbfW/LVM5X8=" crossorigin="anonymous" media="screen" />
  



 




<link rel="icon" type="image/svg+xml" href="/img/favicon.svg" sizes="any">
<link rel="icon" type="image/png" href="/img/favicon-32x32.png" sizes="32x32">
<link rel="icon" type="image/png" href="/img/favicon-16x16.png" sizes="16x16">

<link rel="apple-touch-icon" href="/images/apple-touch-icon.png">
<link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">

<link rel="manifest" href="/site.webmanifest">
<link rel="mask-icon" href="/images/safari-pinned-tab.svg" color="#5bbad5">









</head>






<body class="preload-transitions colorscheme-auto">
  
<div class="float-container">
    <a id="dark-mode-toggle" class="colorscheme-toggle">
        <i class="fa-solid fa-adjust fa-fw" aria-hidden="true"></i>
    </a>
</div>


  <main class="wrapper">
    <nav class="navigation">
  <section class="container">
    
    <a class="navigation-title" href="https://ftxj.github.io/about/">
      JXIN&#39;s Home
    </a>
    
    
      <input type="checkbox" id="menu-toggle" />
      <label class="menu-button float-right" for="menu-toggle">
        <i class="fa-solid fa-bars fa-fw" aria-hidden="true"></i>
      </label>
      <ul class="navigation-list">
        
          
            <li class="navigation-item">
              <a class="navigation-link " href="/about/posts/">Blog</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link " href="/about/about/">About</a>
            </li>
          
        
        
      </ul>
    
  </section>
</nav>


    <div class="content">
      
  <section class="container page">
  <article>
    <header>
      <h1 class="title">
        <a class="title-link" href="https://ftxj.github.io/about/about/">
          About
        </a>
      </h1>
    </header>

    <p>I’m a compute architect at NVIDIA, focused on accelerating Deep Learning software stack on cutting-edge GPUs such as Hopper and Blackwell. Currently, I am engaged in developing a deep learning compiler and enhancing end-to-end training performance. In my spare time, I maintain a keen interest in emerging deep learning algorithms, including embodied intelligence, AI4Science, LLM and graphics.</p>
<p>Some summarizes of my working:</p>
<p>Part of my contribution on Deep Learning Compilers:</p>
<ul>
<li>Fuser (2022): Support graphOps like gather/scatter/index_select. <a href="https://github.com/csarofeen/pytorch/commits/devel/?author=ftxj"  class="external-link" target="_blank" rel="noopener">code</a> <a href="https://pytorch.org/blog/introducing-nvfuser-a-deep-learning-compiler-for-pytorch/"  class="external-link" target="_blank" rel="noopener">blog</a></li>
<li>pytorch_geometric (2022): Add TorchScript support for PyG community. <a href="https://github.com/pyg-team/pytorch_geometric/commits/master/?author=ftxj"  class="external-link" target="_blank" rel="noopener">code</a></li>
</ul>
<p>Part of my contribution on Deep Learning models and frameworks for public users:</p>
<ul>
<li>Openfold (2023): <a href="https://mlcommons.org/benchmarks/training-hpc/"  class="external-link" target="_blank" rel="noopener">MLPerf Training HPC Benchmark Suite Results</a>, round v3.1;
<ul>
<li><a href="https://github.com/mlcommons/hpc_results_v3.0/tree/main/NVIDIA/benchmarks/openfold/implementations/pytorch"  class="external-link" target="_blank" rel="noopener">code</a> <a href="https://developer.nvidia.com/blog/optimizing-openfold-training-for-drug-discovery/"  class="external-link" target="_blank" rel="noopener">blog</a> <a href="https://arxiv.org/abs/2404.11068"  class="external-link" target="_blank" rel="noopener">paper</a></li>
</ul>
</li>
<li>GPT3 (2023): <a href="https://mlcommons.org/benchmarks/training/"  class="external-link" target="_blank" rel="noopener">MLPerf Training Benchmark Suite Results</a>, round v4.0;
<ul>
<li>Support arbitrary combinations of parallel orders. <a href="https://github.com/NVIDIA/Megatron-LM/commit/fbb375d4b5e88ce52f5f7125053068caff47f93f"  class="external-link" target="_blank" rel="noopener">megatron-lm</a> <a href="https://github.com/NVIDIA/NeMo/commit/ac53e2296fcd9f699c928b62948a0b673c3817bc"  class="external-link" target="_blank" rel="noopener">nemo</a></li>
</ul>
</li>
</ul>
<p>Part of my contribution on fast kernels:</p>
<ul>
<li>SpMM optimization (2021): Champion of the <a href="https://graphchallenge.mit.edu/champions"  class="external-link" target="_blank" rel="noopener">Graph Challenge 2021</a>
<ul>
<li><a href="https://github.com/CGCL-codes/Graphchallenge21"  class="external-link" target="_blank" rel="noopener">code</a> <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=9622791"  class="external-link" target="_blank" rel="noopener">paper</a> <a href="https://www.peopleapp.com/column/30038423769-500003439573"  class="external-link" target="_blank" rel="noopener">blog</a></li>
</ul>
</li>
<li>K-Truss decomposition (2021) <a href="https://doi.org/10.1109/HPEC49654.2021.9622792"  class="external-link" target="_blank" rel="noopener">paper</a></li>
</ul>

  </article>
</section>

  

    </div>

    <footer class="footer">
  <section class="container">
    ©
    
      2019 -
    
    2024
     Jie Xin 
    ·
    
    Powered by <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a> & <a href="https://github.com/luizdepra/hugo-coder/" target="_blank" rel="noopener">Coder</a>.
    
  </section>
</footer>

  </main>

  

  
  
  <script src="/about/js/coder.min.6ae284be93d2d19dad1f02b0039508d9aab3180a12a06dcc71b0b0ef7825a317.js" integrity="sha256-auKEvpPS0Z2tHwKwA5UI2aqzGAoSoG3McbCw73gloxc="></script>
  

  

  


  
  



  

  

  

  

  

  

  

  

  

  

  

  

  

  

  
</body>

</html>
